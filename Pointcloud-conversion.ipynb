{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"KPConv-PyTorch/\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imread, imshow\n",
    "import sys\n",
    "from scipy.ndimage import zoom\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "\n",
    "from models.architectures import KPFCNN\n",
    "from utils.config import Config\n",
    "import cpp_wrappers.cpp_neighbors.radius_neighbors as cpp_neighbors\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 3\n",
    "NUM_CHANNEL = 1\n",
    "IMAGE_DEPTH, IMAGE_WIDTH, IMAGE_HEIGHT = 32, 128, 128\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doubts\n",
    "\n",
    "1. What is kernal size of kernal point in KPCOnv class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "1. Dont send all points in dataloader because the GPU usage shoots to 5k GB.\n",
    "2. Try to adapt datasets/S3DIS.py to suit your datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_3d_volume(input_volume, output_shape):\n",
    "    input_shape = input_volume.shape\n",
    "    zoom_factor = output_shape / input_shape\n",
    "    #print(\"Resizing {} to {} by the factor {}\".format(input_shape, output_shape, zoom_factor))\n",
    "    return zoom(input_volume, zoom=zoom_factor)\n",
    "\n",
    "def convert_to_pointcloud(input_array, is_mask = False):\n",
    "    i = 0\n",
    "    if is_mask:\n",
    "        point_cloud = np.ones(shape = (input_array.size, 1))\n",
    "    else:\n",
    "        point_cloud = np.ones(shape = (input_array.size, 4))\n",
    "    for slice_num in range(input_array.shape[0]):\n",
    "        for col_num in range(input_array.shape[1]):\n",
    "            for row_num in range(input_array.shape[2]):\n",
    "                if is_mask:\n",
    "                    point_cloud[i, ] = [input_array[slice_num, row_num, col_num]]\n",
    "                else:\n",
    "                    point_cloud[i, ] = [row_num, col_num, slice_num, input_array[slice_num, row_num, col_num]] \n",
    "                i = i+1\n",
    "    return point_cloud\n",
    "\n",
    "def convert_from_pointcloud(input_pt_cloud):\n",
    "    np_array = input_pt_cloud.size\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellNetConfig(Config):\n",
    "    # dataset\n",
    "    dataset = 'Fluo-C3DH-A549'\n",
    "    num_classes = 2\n",
    "    first_subsampling_dl = 0.02\n",
    "    in_features_dim = 4\n",
    "    data_train_dir = \"./data/Fluo-C3DH-A549/01/\"\n",
    "    data_test_dir = \"./data/Fluo-C3DH-A549/01_GT/\"\n",
    "    train_batch_size = 8\n",
    "    test_batch_size = 8\n",
    "    conv_radius = 2.5\n",
    "    # model\n",
    "    architecture = ['simple',\n",
    "                    'resnetb',\n",
    "                    ]\n",
    "    dropout = 0.5\n",
    "    resume = None\n",
    "    use_batch_norm = True\n",
    "    batch_norm_momentum = 0.02\n",
    "    # https://github.com/pytorch/examples/issues/289 pytorch bn momentum 0.02 == tensorflow bn momentum 0.98\n",
    "\n",
    "    # kernel point convolution\n",
    "    KP_influence = 'linear'\n",
    "    KP_extent = 1.0\n",
    "    convolution_mode = 'sum'\n",
    "\n",
    "    # training\n",
    "    max_epoch = 200\n",
    "    learning_rate = 5e-3\n",
    "    momentum = 0.98\n",
    "    exp_gamma = 0.1 ** (1 / 80)\n",
    "    exp_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = CellNetConfig()\n",
    "model = KPFCNN(cfg, [0, 1], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_row():\n",
    "    def __init__(self, points, features, labels, n_list):\n",
    "        self.points = points.to(device)\n",
    "        self.features = features.to(device)\n",
    "        self.labels = labels.to(device)\n",
    "        self.neighbors = n_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.common import PointCloudDataset\n",
    "class pointcloudDataset(PointCloudDataset):\n",
    "    \"\"\"Cell Segmentation dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, config):\n",
    "        self.root_dir = root_dir\n",
    "        self.config = config\n",
    "        self.batch_size = BATCH_SIZE\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(list(glob(self.root_dir + '_GT/SEG/*.tif')))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        mask_names = glob(self.root_dir + '_GT/SEG/*.tif')\n",
    "        train_image_name = self.root_dir + '/t{}'.format(mask_names[idx][-7:-4] + '.tif')\n",
    "        \n",
    "        train_image = imread(train_image_name)\n",
    "        v_min = train_image.min(axis=(1, 2), keepdims=True)\n",
    "        v_max = train_image.max(axis=(1, 2), keepdims=True)\n",
    "        train_image = ((train_image - v_min)/(v_max - v_min) * 255).astype('uint8')\n",
    "        train_image = resize_3d_volume(train_image, np.array([IMAGE_DEPTH, IMAGE_WIDTH, IMAGE_HEIGHT]))\n",
    "        train_point_cloud = convert_to_pointcloud(train_image)\n",
    "        \n",
    "        print(train_point_cloud)\n",
    "\n",
    "        mask_image = (imread(mask_names[idx]))\n",
    "        mask_image = resize_3d_volume(mask_image, np.array([IMAGE_DEPTH, IMAGE_WIDTH, IMAGE_HEIGHT]))\n",
    "\n",
    "        mask_point_cloud = convert_to_pointcloud(mask_image, is_mask = True)\n",
    "        \n",
    "        points = torch.Tensor(train_point_cloud[:, :3])\n",
    "        features = torch.Tensor(train_point_cloud[:, -1]).reshape(1, -1)\n",
    "        \n",
    "        #features = torch.cat((features, features), 0)\n",
    "        \n",
    "        labels = torch.Tensor(mask_point_cloud)\n",
    "        l = np.array([points.shape[0]], dtype=np.int32)\n",
    "        r_normal = self.config.first_subsampling_dl * self.config.conv_radius\n",
    "#         train_data = np.hstack((train_point_cloud, mask_point_cloud))\n",
    "        \n",
    "        #input_list = segmentation_inputs(train_point_cloud[:, :3], train_point_cloud[:, -1], mask_point_cloud, self.config)\n",
    "        n_list = cpp_neighbors.batch_query(points, points, l, l, radius = 1.5)\n",
    "        \n",
    "        row = data_row(points, features, labels, n_list)\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = pointcloudDataset(\"./data/Fluo-C3DH-A549/01\", cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.  20.]\n",
      " [  1.   0.   0.  57.]\n",
      " [  2.   0.   0.  87.]\n",
      " ...\n",
      " [125. 127.  31.  52.]\n",
      " [126. 127.  31.  11.]\n",
      " [127. 127.  31.   6.]]\n"
     ]
    }
   ],
   "source": [
    "#model.to(device = device)\n",
    "for data in data_loader:\n",
    "#     print(data.features)\n",
    "#     model(data, cfg)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
